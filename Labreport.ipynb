{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8819edab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\parigi sreeja\\desktop\\lab\\.venv\\lib\\site-packages (2.19.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\parigi sreeja\\desktop\\lab\\.venv\\lib\\site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\parigi sreeja\\desktop\\lab\\.venv\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\parigi sreeja\\desktop\\lab\\.venv\\lib\\site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\parigi sreeja\\desktop\\lab\\.venv\\lib\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\parigi sreeja\\desktop\\lab\\.venv\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\parigi sreeja\\desktop\\lab\\.venv\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\parigi sreeja\\desktop\\lab\\.venv\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\parigi sreeja\\desktop\\lab\\.venv\\lib\\site-packages (from tensorflow) (25.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\parigi sreeja\\desktop\\lab\\.venv\\lib\\site-packages (from tensorflow) (5.29.5)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\parigi sreeja\\desktop\\lab\\.venv\\lib\\site-packages (from tensorflow) (2.32.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\parigi sreeja\\desktop\\lab\\.venv\\lib\\site-packages (from tensorflow) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\parigi sreeja\\desktop\\lab\\.venv\\lib\\site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\parigi sreeja\\desktop\\lab\\.venv\\lib\\site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\parigi sreeja\\desktop\\lab\\.venv\\lib\\site-packages (from tensorflow) (4.14.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\parigi sreeja\\desktop\\lab\\.venv\\lib\\site-packages (from tensorflow) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\parigi sreeja\\desktop\\lab\\.venv\\lib\\site-packages (from tensorflow) (1.73.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in c:\\users\\parigi sreeja\\desktop\\lab\\.venv\\lib\\site-packages (from tensorflow) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\parigi sreeja\\desktop\\lab\\.venv\\lib\\site-packages (from tensorflow) (3.10.0)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in c:\\users\\parigi sreeja\\desktop\\lab\\.venv\\lib\\site-packages (from tensorflow) (2.1.3)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\parigi sreeja\\desktop\\lab\\.venv\\lib\\site-packages (from tensorflow) (3.14.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in c:\\users\\parigi sreeja\\desktop\\lab\\.venv\\lib\\site-packages (from tensorflow) (0.5.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\parigi sreeja\\desktop\\lab\\.venv\\lib\\site-packages (from tensorflow) (0.31.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\parigi sreeja\\desktop\\lab\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\parigi sreeja\\desktop\\lab\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\parigi sreeja\\desktop\\lab\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\parigi sreeja\\desktop\\lab\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\parigi sreeja\\desktop\\lab\\.venv\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.8)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\parigi sreeja\\desktop\\lab\\.venv\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\parigi sreeja\\desktop\\lab\\.venv\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\parigi sreeja\\desktop\\lab\\.venv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\parigi sreeja\\desktop\\lab\\.venv\\lib\\site-packages (from keras>=3.5.0->tensorflow) (14.0.0)\n",
      "Requirement already satisfied: namex in c:\\users\\parigi sreeja\\desktop\\lab\\.venv\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in c:\\users\\parigi sreeja\\desktop\\lab\\.venv\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\parigi sreeja\\desktop\\lab\\.venv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\parigi sreeja\\desktop\\lab\\.venv\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\parigi sreeja\\desktop\\lab\\.venv\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\parigi sreeja\\desktop\\lab\\.venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d89d3f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8575 - loss: 0.5034\n",
      "Epoch 2/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9525 - loss: 0.1652\n",
      "Epoch 3/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9658 - loss: 0.1154\n",
      "Epoch 4/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9747 - loss: 0.0876\n",
      "Epoch 5/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9774 - loss: 0.0714\n",
      "TF Training time: 15.40 seconds\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9677 - loss: 0.1104\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0948181003332138, 0.9715999960899353]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import time\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train / 255   # Fill in normalization factor\n",
    "x_test = x_test / 255     # Fill in normalization factor\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(28, 28)),        # Fill input shape\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),  # Fill number of hidden neurons\n",
    "    tf.keras.layers.Dense(10, activation='softmax')  # Fill number of output neurons\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',       # Fill name of loss function\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "start = time.time()\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "end = time.time()\n",
    "print(f\"TF Training time: {end-start:.2f} seconds\")       # Output training time\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a5e8449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\PARIGI~1\\AppData\\Local\\Temp\\tmpl2ooo4ye\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\PARIGI~1\\AppData\\Local\\Temp\\tmpl2ooo4ye\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'C:\\Users\\PARIGI~1\\AppData\\Local\\Temp\\tmpl2ooo4ye'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 28, 28), dtype=tf.float32, name='keras_tensor')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 10), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  2959000558032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2959000558992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2959000558416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2959000558800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open(\"model.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1005280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\parigi sreeja\\desktop\\lab\\.venv\\lib\\site-packages (2.7.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\parigi sreeja\\desktop\\lab\\.venv\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\parigi sreeja\\desktop\\lab\\.venv\\lib\\site-packages (from torch) (4.14.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\parigi sreeja\\desktop\\lab\\.venv\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\parigi sreeja\\desktop\\lab\\.venv\\lib\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\parigi sreeja\\desktop\\lab\\.venv\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\parigi sreeja\\desktop\\lab\\.venv\\lib\\site-packages (from torch) (2025.5.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\parigi sreeja\\desktop\\lab\\.venv\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\parigi sreeja\\desktop\\lab\\.venv\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4ea291e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in c:\\users\\parigi sreeja\\desktop\\lab\\.venv\\lib\\site-packages (0.22.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\parigi sreeja\\desktop\\lab\\.venv\\lib\\site-packages (from torchvision) (2.1.3)\n",
      "Requirement already satisfied: torch==2.7.1 in c:\\users\\parigi sreeja\\desktop\\lab\\.venv\\lib\\site-packages (from torchvision) (2.7.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\parigi sreeja\\desktop\\lab\\.venv\\lib\\site-packages (from torchvision) (11.2.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\parigi sreeja\\desktop\\lab\\.venv\\lib\\site-packages (from torch==2.7.1->torchvision) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\parigi sreeja\\desktop\\lab\\.venv\\lib\\site-packages (from torch==2.7.1->torchvision) (4.14.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\parigi sreeja\\desktop\\lab\\.venv\\lib\\site-packages (from torch==2.7.1->torchvision) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\parigi sreeja\\desktop\\lab\\.venv\\lib\\site-packages (from torch==2.7.1->torchvision) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\parigi sreeja\\desktop\\lab\\.venv\\lib\\site-packages (from torch==2.7.1->torchvision) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\parigi sreeja\\desktop\\lab\\.venv\\lib\\site-packages (from torch==2.7.1->torchvision) (2025.5.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\parigi sreeja\\desktop\\lab\\.venv\\lib\\site-packages (from sympy>=1.13.3->torch==2.7.1->torchvision) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\parigi sreeja\\desktop\\lab\\.venv\\lib\\site-packages (from jinja2->torch==2.7.1->torchvision) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a0417cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Training time: 65.69 seconds\n",
      "Test accuracy: 0.9661\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Transform: Convert to tensor and flatten 28x28 -> 784\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: x.view(-1))  # Flatten\n",
    "])\n",
    "\n",
    "# Loaders\n",
    "train_loader = DataLoader(datasets.MNIST(root='./data', train=True, transform=transform, download=True), batch_size=32)\n",
    "test_loader = DataLoader(datasets.MNIST(root='./data', train=False, transform=transform, download=True), batch_size=1000)\n",
    "\n",
    "# Define Model\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 64)   # Input size 784 (28x28), hidden layer with 64 units\n",
    "        self.fc2 = nn.Linear(64, 10)    # Hidden to 10 output classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))         # First layer + ReLU\n",
    "        return self.fc2(x)              # Output layer (raw logits)\n",
    "\n",
    "# Instantiate model\n",
    "model = Net()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training loop\n",
    "start = time.time()\n",
    "for epoch in range(5):\n",
    "    for x, y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(x)\n",
    "        loss = loss_fn(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "end = time.time()\n",
    "print(f\"PyTorch Training time: {end - start:.2f} seconds\")\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    for x, y in test_loader:\n",
    "        output = model(x)\n",
    "        pred = output.argmax(1)\n",
    "        correct += (pred == y).sum().item()\n",
    "\n",
    "print(f\"Test accuracy: {correct / len(test_loader.dataset):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98a45221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: onnx in c:\\users\\parigi sreeja\\desktop\\lab\\.venv\\lib\\site-packages (1.18.0)\n",
      "Requirement already satisfied: numpy>=1.22 in c:\\users\\parigi sreeja\\desktop\\lab\\.venv\\lib\\site-packages (from onnx) (2.1.3)\n",
      "Requirement already satisfied: protobuf>=4.25.1 in c:\\users\\parigi sreeja\\desktop\\lab\\.venv\\lib\\site-packages (from onnx) (5.29.5)\n",
      "Requirement already satisfied: typing_extensions>=4.7.1 in c:\\users\\parigi sreeja\\desktop\\lab\\.venv\\lib\\site-packages (from onnx) (4.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6e881c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_input = torch.randn(1, 784)\n",
    "torch.onnx.export(model, dummy_input, \"model.onnx\",\n",
    "                  input_names=[\"input\"], output_names=[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7106f3b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/5\n",
      "Step 0, Loss: 2.4941, Accuracy: 0.0938\n",
      "Step 100, Loss: 0.6565, Accuracy: 0.7163\n",
      "Step 200, Loss: 0.2605, Accuracy: 0.7951\n",
      "Step 300, Loss: 0.3571, Accuracy: 0.8293\n",
      "Step 400, Loss: 0.3814, Accuracy: 0.8489\n",
      "Step 500, Loss: 0.2175, Accuracy: 0.8623\n",
      "Step 600, Loss: 0.1476, Accuracy: 0.8707\n",
      "Step 700, Loss: 0.1284, Accuracy: 0.8777\n",
      "Step 800, Loss: 0.2657, Accuracy: 0.8838\n",
      "Step 900, Loss: 0.1583, Accuracy: 0.8881\n",
      "Step 1000, Loss: 0.1333, Accuracy: 0.8923\n",
      "Step 1100, Loss: 0.2524, Accuracy: 0.8963\n",
      "Step 1200, Loss: 0.2566, Accuracy: 0.8995\n",
      "Step 1300, Loss: 0.1443, Accuracy: 0.9028\n",
      "Step 1400, Loss: 0.2683, Accuracy: 0.9052\n",
      "Step 1500, Loss: 0.0969, Accuracy: 0.9074\n",
      "Step 1600, Loss: 0.1453, Accuracy: 0.9098\n",
      "Step 1700, Loss: 0.0367, Accuracy: 0.9123\n",
      "Step 1800, Loss: 0.1156, Accuracy: 0.9143\n",
      "Training Accuracy for epoch 1: 0.9159\n",
      "\n",
      "Epoch 2/5\n",
      "Step 0, Loss: 0.1746, Accuracy: 0.9062\n",
      "Step 100, Loss: 0.0886, Accuracy: 0.9514\n",
      "Step 200, Loss: 0.1643, Accuracy: 0.9518\n",
      "Step 300, Loss: 0.0844, Accuracy: 0.9521\n",
      "Step 400, Loss: 0.0667, Accuracy: 0.9532\n",
      "Step 500, Loss: 0.0485, Accuracy: 0.9529\n",
      "Step 600, Loss: 0.0838, Accuracy: 0.9533\n",
      "Step 700, Loss: 0.0623, Accuracy: 0.9545\n",
      "Step 800, Loss: 0.0207, Accuracy: 0.9551\n",
      "Step 900, Loss: 0.1962, Accuracy: 0.9557\n",
      "Step 1000, Loss: 0.1139, Accuracy: 0.9562\n",
      "Step 1100, Loss: 0.2363, Accuracy: 0.9556\n",
      "Step 1200, Loss: 0.1390, Accuracy: 0.9558\n",
      "Step 1300, Loss: 0.0936, Accuracy: 0.9563\n",
      "Step 1400, Loss: 0.1392, Accuracy: 0.9562\n",
      "Step 1500, Loss: 0.0967, Accuracy: 0.9559\n",
      "Step 1600, Loss: 0.3538, Accuracy: 0.9564\n",
      "Step 1700, Loss: 0.1355, Accuracy: 0.9569\n",
      "Step 1800, Loss: 0.1264, Accuracy: 0.9576\n",
      "Training Accuracy for epoch 2: 0.9580\n",
      "\n",
      "Epoch 3/5\n",
      "Step 0, Loss: 0.0334, Accuracy: 1.0000\n",
      "Step 100, Loss: 0.0496, Accuracy: 0.9691\n",
      "Step 200, Loss: 0.0760, Accuracy: 0.9691\n",
      "Step 300, Loss: 0.1566, Accuracy: 0.9677\n",
      "Step 400, Loss: 0.0132, Accuracy: 0.9670\n",
      "Step 500, Loss: 0.2015, Accuracy: 0.9669\n",
      "Step 600, Loss: 0.1401, Accuracy: 0.9668\n",
      "Step 700, Loss: 0.0472, Accuracy: 0.9667\n",
      "Step 800, Loss: 0.0685, Accuracy: 0.9672\n",
      "Step 900, Loss: 0.3909, Accuracy: 0.9674\n",
      "Step 1000, Loss: 0.0897, Accuracy: 0.9673\n",
      "Step 1100, Loss: 0.0235, Accuracy: 0.9678\n",
      "Step 1200, Loss: 0.0415, Accuracy: 0.9676\n",
      "Step 1300, Loss: 0.0645, Accuracy: 0.9675\n",
      "Step 1400, Loss: 0.1650, Accuracy: 0.9674\n",
      "Step 1500, Loss: 0.0046, Accuracy: 0.9678\n",
      "Step 1600, Loss: 0.1401, Accuracy: 0.9683\n",
      "Step 1700, Loss: 0.0924, Accuracy: 0.9685\n",
      "Step 1800, Loss: 0.0134, Accuracy: 0.9688\n",
      "Training Accuracy for epoch 3: 0.9689\n",
      "\n",
      "Epoch 4/5\n",
      "Step 0, Loss: 0.1359, Accuracy: 0.9688\n",
      "Step 100, Loss: 0.0234, Accuracy: 0.9718\n",
      "Step 200, Loss: 0.0335, Accuracy: 0.9751\n",
      "Step 300, Loss: 0.0808, Accuracy: 0.9752\n",
      "Step 400, Loss: 0.0044, Accuracy: 0.9752\n",
      "Step 500, Loss: 0.2268, Accuracy: 0.9749\n",
      "Step 600, Loss: 0.0676, Accuracy: 0.9741\n",
      "Step 700, Loss: 0.0100, Accuracy: 0.9742\n",
      "Step 800, Loss: 0.0147, Accuracy: 0.9747\n",
      "Step 900, Loss: 0.0286, Accuracy: 0.9745\n",
      "Step 1000, Loss: 0.0319, Accuracy: 0.9744\n",
      "Step 1100, Loss: 0.0142, Accuracy: 0.9749\n",
      "Step 1200, Loss: 0.0085, Accuracy: 0.9749\n",
      "Step 1300, Loss: 0.0319, Accuracy: 0.9747\n",
      "Step 1400, Loss: 0.0699, Accuracy: 0.9745\n",
      "Step 1500, Loss: 0.2829, Accuracy: 0.9743\n",
      "Step 1600, Loss: 0.0679, Accuracy: 0.9743\n",
      "Step 1700, Loss: 0.0481, Accuracy: 0.9746\n",
      "Step 1800, Loss: 0.0144, Accuracy: 0.9748\n",
      "Training Accuracy for epoch 4: 0.9748\n",
      "\n",
      "Epoch 5/5\n",
      "Step 0, Loss: 0.0215, Accuracy: 1.0000\n",
      "Step 100, Loss: 0.0691, Accuracy: 0.9777\n",
      "Step 200, Loss: 0.0877, Accuracy: 0.9798\n",
      "Step 300, Loss: 0.0529, Accuracy: 0.9797\n",
      "Step 400, Loss: 0.0268, Accuracy: 0.9793\n",
      "Step 500, Loss: 0.0200, Accuracy: 0.9799\n",
      "Step 600, Loss: 0.0407, Accuracy: 0.9791\n",
      "Step 700, Loss: 0.0502, Accuracy: 0.9790\n",
      "Step 800, Loss: 0.1363, Accuracy: 0.9790\n",
      "Step 900, Loss: 0.3713, Accuracy: 0.9786\n",
      "Step 1000, Loss: 0.0509, Accuracy: 0.9787\n",
      "Step 1100, Loss: 0.0516, Accuracy: 0.9789\n",
      "Step 1200, Loss: 0.0701, Accuracy: 0.9789\n",
      "Step 1300, Loss: 0.0498, Accuracy: 0.9790\n",
      "Step 1400, Loss: 0.0409, Accuracy: 0.9790\n",
      "Step 1500, Loss: 0.0125, Accuracy: 0.9791\n",
      "Step 1600, Loss: 0.0543, Accuracy: 0.9793\n",
      "Step 1700, Loss: 0.0085, Accuracy: 0.9795\n",
      "Step 1800, Loss: 0.0085, Accuracy: 0.9792\n",
      "Training Accuracy for epoch 5: 0.9792\n",
      "\n",
      "TF Training time: 215.02 seconds\n",
      "Test Accuracy: 0.9693\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import time\n",
    "\n",
    "# Load and preprocess data\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train / 255.0   # Normalization factor: scale to [0, 1]\n",
    "x_test = x_test / 255.0     # Same here\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "# Prepare datasets\n",
    "batch_size = 32         # Same batch size as in first TF example\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(10000).batch(batch_size)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(batch_size)\n",
    "\n",
    "# Define model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(28, 28)),           # MNIST images are 28x28\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),    # Hidden layer with 64 neurons and ReLU activation\n",
    "    tf.keras.layers.Dense(10, activation='softmax')  # Output layer with 10 neurons and softmax\n",
    "])\n",
    "\n",
    "# Define loss, optimizer, and metrics\n",
    "loss_fn = tf.keras.losses.CategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "train_acc_metric = tf.keras.metrics.CategoricalAccuracy()\n",
    "test_acc_metric = tf.keras.metrics.CategoricalAccuracy()\n",
    "\n",
    "# Training loop\n",
    "epochs = 5\n",
    "start = time.time()\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
    "    for step, (x_batch, y_batch) in enumerate(train_dataset):\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = model(x_batch, training=True)\n",
    "            loss = loss_fn(y_batch, logits)\n",
    "        grads = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "        train_acc_metric.update_state(y_batch, logits)\n",
    "\n",
    "        if step % 100 == 0:\n",
    "            print(f\"Step {step}, Loss: {loss.numpy():.4f}, Accuracy: {train_acc_metric.result().numpy():.4f}\")\n",
    "\n",
    "    print(f\"Training Accuracy for epoch {epoch+1}: {train_acc_metric.result().numpy():.4f}\")\n",
    "    train_acc_metric.reset_state()\n",
    "end = time.time()\n",
    "print(f\"\\nTF Training time: {end - start:.2f} seconds\")\n",
    "\n",
    "# Evaluation loop\n",
    "for x_batch, y_batch in test_dataset:\n",
    "    test_logits = model(x_batch, training=False)\n",
    "    test_acc_metric.update_state(y_batch, test_logits)\n",
    "\n",
    "print(f\"Test Accuracy: {test_acc_metric.result().numpy():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ff75dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/5\n",
      "Step 0, Loss: 2.3744, Accuracy: 0.0625\n",
      "Step 100, Loss: 0.5307, Accuracy: 0.7259\n",
      "Step 200, Loss: 0.6945, Accuracy: 0.7973\n",
      "Step 300, Loss: 0.3799, Accuracy: 0.8291\n",
      "Step 400, Loss: 0.1824, Accuracy: 0.8495\n",
      "Step 500, Loss: 0.2466, Accuracy: 0.8632\n",
      "Step 600, Loss: 0.0566, Accuracy: 0.8717\n",
      "Step 700, Loss: 0.2934, Accuracy: 0.8791\n",
      "Step 800, Loss: 0.3144, Accuracy: 0.8845\n",
      "Step 900, Loss: 0.2282, Accuracy: 0.8883\n",
      "Step 1000, Loss: 0.1397, Accuracy: 0.8923\n",
      "Step 1100, Loss: 0.1488, Accuracy: 0.8955\n",
      "Step 1200, Loss: 0.3757, Accuracy: 0.8987\n",
      "Step 1300, Loss: 0.3101, Accuracy: 0.9016\n",
      "Step 1400, Loss: 0.1963, Accuracy: 0.9038\n",
      "Step 1500, Loss: 0.1458, Accuracy: 0.9060\n",
      "Step 1600, Loss: 0.1349, Accuracy: 0.9083\n",
      "Step 1700, Loss: 0.3246, Accuracy: 0.9110\n",
      "Step 1800, Loss: 0.0778, Accuracy: 0.9131\n",
      "Training Accuracy for epoch 1: 0.9144\n",
      "\n",
      "Epoch 2/5\n",
      "Step 0, Loss: 0.4738, Accuracy: 0.8750\n",
      "Step 100, Loss: 0.0879, Accuracy: 0.9489\n",
      "Step 200, Loss: 0.2489, Accuracy: 0.9510\n",
      "Step 300, Loss: 0.0312, Accuracy: 0.9511\n",
      "Step 400, Loss: 0.0954, Accuracy: 0.9505\n",
      "Step 500, Loss: 0.1550, Accuracy: 0.9512\n",
      "Step 600, Loss: 0.2499, Accuracy: 0.9522\n",
      "Step 700, Loss: 0.1776, Accuracy: 0.9531\n",
      "Step 800, Loss: 0.2580, Accuracy: 0.9533\n",
      "Step 900, Loss: 0.0473, Accuracy: 0.9533\n",
      "Step 1000, Loss: 0.1271, Accuracy: 0.9535\n",
      "Step 1100, Loss: 0.0230, Accuracy: 0.9540\n",
      "Step 1200, Loss: 0.1292, Accuracy: 0.9544\n",
      "Step 1300, Loss: 0.0685, Accuracy: 0.9545\n",
      "Step 1400, Loss: 0.1010, Accuracy: 0.9548\n",
      "Step 1500, Loss: 0.1146, Accuracy: 0.9547\n",
      "Step 1600, Loss: 0.2478, Accuracy: 0.9556\n",
      "Step 1700, Loss: 0.0466, Accuracy: 0.9559\n",
      "Step 1800, Loss: 0.0813, Accuracy: 0.9566\n",
      "Training Accuracy for epoch 2: 0.9570\n",
      "\n",
      "Epoch 3/5\n",
      "Step 0, Loss: 0.1252, Accuracy: 0.9688\n",
      "Step 100, Loss: 0.0736, Accuracy: 0.9706\n",
      "Step 200, Loss: 0.0367, Accuracy: 0.9681\n",
      "Step 300, Loss: 0.0527, Accuracy: 0.9679\n",
      "Step 400, Loss: 0.0698, Accuracy: 0.9675\n",
      "Step 500, Loss: 0.0734, Accuracy: 0.9666\n",
      "Step 600, Loss: 0.1198, Accuracy: 0.9661\n",
      "Step 700, Loss: 0.2789, Accuracy: 0.9663\n",
      "Step 800, Loss: 0.0645, Accuracy: 0.9663\n",
      "Step 900, Loss: 0.0244, Accuracy: 0.9668\n",
      "Step 1000, Loss: 0.0121, Accuracy: 0.9668\n",
      "Step 1100, Loss: 0.0813, Accuracy: 0.9670\n",
      "Step 1200, Loss: 0.0277, Accuracy: 0.9670\n",
      "Step 1300, Loss: 0.1853, Accuracy: 0.9667\n",
      "Step 1400, Loss: 0.0681, Accuracy: 0.9664\n",
      "Step 1500, Loss: 0.1047, Accuracy: 0.9666\n",
      "Step 1600, Loss: 0.0516, Accuracy: 0.9670\n",
      "Step 1700, Loss: 0.1746, Accuracy: 0.9672\n",
      "Step 1800, Loss: 0.0298, Accuracy: 0.9676\n",
      "Training Accuracy for epoch 3: 0.9678\n",
      "\n",
      "Epoch 4/5\n",
      "Step 0, Loss: 0.0123, Accuracy: 1.0000\n",
      "Step 100, Loss: 0.5724, Accuracy: 0.9728\n",
      "Step 200, Loss: 0.0577, Accuracy: 0.9729\n",
      "Step 300, Loss: 0.0221, Accuracy: 0.9741\n",
      "Step 400, Loss: 0.1540, Accuracy: 0.9746\n",
      "Step 500, Loss: 0.1724, Accuracy: 0.9729\n",
      "Step 600, Loss: 0.2769, Accuracy: 0.9726\n",
      "Step 700, Loss: 0.0425, Accuracy: 0.9733\n",
      "Step 800, Loss: 0.0325, Accuracy: 0.9734\n",
      "Step 900, Loss: 0.0549, Accuracy: 0.9738\n",
      "Step 1000, Loss: 0.0098, Accuracy: 0.9742\n",
      "Step 1100, Loss: 0.1644, Accuracy: 0.9744\n",
      "Step 1200, Loss: 0.0308, Accuracy: 0.9744\n",
      "Step 1300, Loss: 0.0281, Accuracy: 0.9744\n",
      "Step 1400, Loss: 0.0284, Accuracy: 0.9744\n",
      "Step 1500, Loss: 0.0249, Accuracy: 0.9744\n",
      "Step 1600, Loss: 0.0483, Accuracy: 0.9742\n",
      "Step 1700, Loss: 0.0377, Accuracy: 0.9744\n",
      "Step 1800, Loss: 0.0305, Accuracy: 0.9745\n",
      "Training Accuracy for epoch 4: 0.9746\n",
      "\n",
      "Epoch 5/5\n",
      "Step 0, Loss: 0.0297, Accuracy: 1.0000\n",
      "Step 100, Loss: 0.0115, Accuracy: 0.9817\n",
      "Step 200, Loss: 0.0467, Accuracy: 0.9821\n",
      "Step 300, Loss: 0.0252, Accuracy: 0.9800\n",
      "Step 400, Loss: 0.0188, Accuracy: 0.9794\n",
      "Step 500, Loss: 0.0046, Accuracy: 0.9796\n",
      "Step 600, Loss: 0.0664, Accuracy: 0.9790\n",
      "Step 700, Loss: 0.0424, Accuracy: 0.9791\n",
      "Step 800, Loss: 0.0514, Accuracy: 0.9794\n",
      "Step 900, Loss: 0.0717, Accuracy: 0.9800\n",
      "Step 1000, Loss: 0.0348, Accuracy: 0.9799\n",
      "Step 1100, Loss: 0.0393, Accuracy: 0.9794\n",
      "Step 1200, Loss: 0.0557, Accuracy: 0.9797\n",
      "Step 1300, Loss: 0.0409, Accuracy: 0.9794\n",
      "Step 1400, Loss: 0.0046, Accuracy: 0.9786\n",
      "Step 1500, Loss: 0.0288, Accuracy: 0.9786\n",
      "Step 1600, Loss: 0.0567, Accuracy: 0.9786\n",
      "Step 1700, Loss: 0.0951, Accuracy: 0.9789\n",
      "Step 1800, Loss: 0.0629, Accuracy: 0.9791\n",
      "Training Accuracy for epoch 5: 0.9791\n",
      "\n",
      "TF Training time: 13.12 seconds\n",
      "Test Accuracy: 0.9704\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import time\n",
    "\n",
    "# Load and preprocess data\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train / 255.0   # Normalize to [0, 1]\n",
    "x_test = x_test / 255.0\n",
    "y_train = to_categorical(y_train, num_classes=10)\n",
    "y_test = to_categorical(y_test, num_classes=10)\n",
    "\n",
    "# Prepare datasets\n",
    "batch_size = 32\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(10000).batch(batch_size)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(batch_size)\n",
    "\n",
    "# Define model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(28, 28)),         # MNIST images are 28x28\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),  # Hidden layer with 64 neurons and ReLU activation\n",
    "    tf.keras.layers.Dense(10, activation='softmax')# Output layer with 10 neurons (for 10 classes)\n",
    "])\n",
    "\n",
    "# Define loss, optimizer, and metrics\n",
    "loss_fn = tf.keras.losses.CategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "train_acc_metric = tf.keras.metrics.CategoricalAccuracy()\n",
    "test_acc_metric = tf.keras.metrics.CategoricalAccuracy()\n",
    "\n",
    "@tf.function  # compile the function into a graph\n",
    "def train_step(x_batch, y_batch):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = model(x_batch, training=True)\n",
    "        loss = loss_fn(y_batch, logits)\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    train_acc_metric.update_state(y_batch, logits)\n",
    "    return loss\n",
    "\n",
    "# Training loop\n",
    "epochs = 5\n",
    "start = time.time()\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
    "    for step, (x_batch, y_batch) in enumerate(train_dataset):\n",
    "        loss = train_step(x_batch, y_batch)\n",
    "\n",
    "        if step % 100 == 0:\n",
    "            print(f\"Step {step}, Loss: {loss.numpy():.4f}, Accuracy: {train_acc_metric.result().numpy():.4f}\")\n",
    "\n",
    "    print(f\"Training Accuracy for epoch {epoch+1}: {train_acc_metric.result().numpy():.4f}\")\n",
    "    train_acc_metric.reset_state()\n",
    "end = time.time()\n",
    "print(f\"\\nTF Training time: {end - start:.2f} seconds\")\n",
    "\n",
    "# Evaluation loop\n",
    "for x_batch, y_batch in test_dataset:\n",
    "    test_logits = model(x_batch, training=False)\n",
    "    test_acc_metric.update_state(y_batch, test_logits)\n",
    "\n",
    "print(f\"Test Accuracy: {test_acc_metric.result().numpy():.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
